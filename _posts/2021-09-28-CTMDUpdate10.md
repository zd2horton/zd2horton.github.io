---
layout: post
title: Creative Technologies Master Dissertation Update 10
date: 2021-09-28
excerpt: Attempting to create a model, and supervisor advice.
tags: [CTMD, post, CTMDpost]
CTMDpost: true
category: post
published: true
comments: true
---
During supervisor discussion, it was suggested that different algorithms could be analysed as potential implementations, as well as for the evaluation and writeup. This would assist in fortifying the hypothesis, as while the implementation could work for PPO, SAC could otherwise prove to be more difficult and thus give way for a more distinct method for the AI agent to learn through. To add, the theme of the agents potentially exploring areas playtesters and developers could not was also touched upon and discussed, as it may be likely that they encounter strange events in the game (e.g: hovering on walls) due to being controlled in potentially unorthodox ways. These events in turn would help incredibly with encountering and fixing bugs for a more refined playable product, especially in cases in which a human playtester may not be able to find the aforementioned bugs. 

Alongside this, the handful of levels for the project have been fully created. The first gives the smallest challenge to both testers, with a beginning area to learn about collectables and enemies before a sequence of small jumps that can be retried if failed, including the aforementioned elements. This is then followed by a single change in direction, after which sprint jumps are introduced before a demonstration of the falling block at the end which, even if failed, can be attempted without. This layout should be able to be simple for the agent to learn due to its lesser difficulty, and is the least fleshed out of the three as to test the potential parallel.

The second is notably more focused on jumps, opening with a short trial of downward jumps which once more prepare the playtester before transitioning into a falling segment. If the playtester falls at this point however, they are not counted out as they instead fall into a slower route leading up to the main, fleshing the level out more and assisting in making the level more playable. This in turn is followed up by the provided double jump powerup, giving the ability for the testers to continue on with the level's main and optional setpieces at the end of the level. Though more challenging for the testers due to context sensitive information such as alternate routes and a required power-up, the content has been developed as to garner more user engagement than the previous layout. 

The final level is notably crafted for this purpose, having segments fully testing the playtesters' skills and creating a far more lively map with areas such as alternate routes and optional areas to reward exploration and power-up knowledge. While it may be impossible for the agent to take advantage of every aspect of the level, the features may correlate with overall playtester enjoyment and thus with the other levels assist the hypothesis even further.

Various quality of life factors such as container blocks have been created as to assist with fleshing levels out, with multiple prefabs being required in order to accomodate for fixed item spawning due to tile assets not taking into account variable factors that could usually condense the task into a single block. These blocks in turn to help with both the agent and human players have also been altered to drop the contained item through increasing its gravity and destroy the empty block, as previous attempts to claim the item were often difficult due to the block's height. 

Finally, a machine learning script has begun to take root with various aspects such as the agent goals (the level exit and currently, a single coin), initial positions of both agent and target, and standard agent factors being either refreshed with each episode or initialised at the beginning. The script then collects observations that may be required (target and agent positions, health) and also takes control of the player control variables through continuous actions (fed through Heuristics currently) dictated by the agent's academy in OnActionReceived. Following this, the script will then add a negative reward if health depletes to 0 or the agent touches a death plane, and will alternatively reward the agent positively if the coin is touched. Currently, as progress on the levels has been completed, attention will now shift to gradually developing and improving the agent to potentially complete the content at hand.

Level 1:
<a href="https://i.imgur.com/QC5SGAG.png"><img src="https://i.imgur.com/QC5SGAG.png"></a>

Level 2:
<a href="https://i.imgur.com/VORG0WU.png"><img src="https://i.imgur.com/VORG0WU.png"></a>

Level 3:
<a href="https://i.imgur.com/yxhFodw.png"><img src="https://i.imgur.com/yxhFodw.png"></a>

<a href="https://i.imgur.com/TBpfsDz.png"><img src="https://i.imgur.com/TBpfsDz.png"></a>